{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2018-CS109A/blob/master/content/styles/iacs.png?raw=true\"> CS109A/STAT121A/AC209A/CSCIE109A  Introduction to Data Science \n",
    "\n",
    "\n",
    "## Lab 3: plotting, K-NN Regression, Simple Linear Regression\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2019**<br>\n",
    "**Instructors:** Pavlos Protopapas, Kevin Rader, and Chris Tanner<br>\n",
    "\n",
    "**Material prepared by**: David Sondak, Will Claybaugh, Pavlos Protopapas, and Eleni Kaxiras.\n",
    "\n",
    "## <font color='red'> Extended Edition</font>\n",
    "\n",
    "Same as the one done in class with the following additions/clarifications:\n",
    "\n",
    "* I added another example to illustrate the difference between `.iloc` and `.loc` in `pandas` -- > [here](#iloc)\n",
    "* How to run the solutions: Uncomment the following line and run the cell:\n",
    "\n",
    "```python\n",
    "# %load solutions/knn_regression.py\n",
    "```\n",
    "This will bring up the code in the cell but WILL NOT RUN it. You need to run the cell again in order to actually run the code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Review `numpy` including 2-D arrays and understand array reshaping\n",
    "* Use `matplotlib` to make plots\n",
    "* Feel comfortable with simple linear regression\n",
    "* Feel comfortable with $k$ nearest neighbors\n",
    "\n",
    "**This lab corresponds to lectures 4 and 5 and maps on to homework 2 and beyond.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### <font color='red'> HIGHLIGHTS FROM PRE-LAB </font>\n",
    "\n",
    "* [1 - Review of numpy](#first-bullet)\n",
    "* [2 - Intro to matplotlib plus more ](#second-bullet)\n",
    "\n",
    "#### <font color='red'> LAB 3 MATERIAL </font>\n",
    "\n",
    "* [3 - Simple Linear Regression](#third-bullet)\n",
    "* [4 - Building a model with `statsmodels` and `sklearn`](#fourth-bullet)\n",
    "* [5 - Example: Simple linear regression with automobile data](#fifth-bullet)\n",
    "* [6 - $k$Nearest Neighbors](#sixth-bullet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Displays the plots for us.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as a variable to load solutions: %load PATHTOSOLUTIONS/exercise1.py. It will be substituted in the code\n",
    "# so do not worry if it disappears after you run the cell.\n",
    "PATHTOSOLUTIONS = 'solutions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "## 1 - Review of  the  `numpy` Python library\n",
    "\n",
    "In lab1 we learned about the `numpy` library [(documentation)](http://www.numpy.org/) and its fast array structure, called the `numpy array`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an array\n",
    "my_array = np.array([1,4,9,16])\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size of my array: {my_array.size}, or length of my array: {len(my_array)}')\n",
    "print (f'Shape of my array: {my_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the way the shape appears in numpy arrays\n",
    "\n",
    "- For a 1D array, .shape returns a tuple with 1 element (n,)\n",
    "- For a 2D array, .shape returns a tuple with 2 elements (n,m)\n",
    "- For a 3D array, .shape returns a tuple with 3 elements (n,m,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to reshape a 1D array to a 2D\n",
    "my_array.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays support the same operations as lists! Below we slice and iterate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"array[2:4]:\", my_array[2:4]) # A slice of the array\n",
    "\n",
    "# Iterate over the array\n",
    "for ele in my_array:\n",
    "    print(\"element:\", ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember `numpy` gains a lot of its efficiency from being **strongly typed** (all elements are of the same type, such as integer or floating point). If the elements of an array are of a different type, `numpy` will force them into the same type (the longest in terms of bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = np.array([1, 2.3, 'eleni', True])\n",
    "print(type(1), type(2.3), type('eleni'), type(True))\n",
    "mixed # all elements will become strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we push ahead to two-dimensional arrays and begin to dive into some of the deeper aspects of `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a 2d-array by handing a list of lists\n",
    "my_array2d = np.array([ [1, 2, 3, 4], \n",
    "                        [5, 6, 7, 8], \n",
    "                        [9, 10, 11, 12] \n",
    "])\n",
    "\n",
    "my_array2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Slicing (a reminder...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays can be sliced, and can be iterated over with loops.  Below is a schematic illustrating slicing two-dimensional arrays.  \n",
    "\n",
    " <img src=\"../images/2dindex_v2.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " \n",
    "Notice that the list slicing syntax still works!  \n",
    "`array[2:,3]` says \"in the array, get rows 2 through the end, column 3]\"  \n",
    "`array[3,:]` says \"in the array, get row 3, all columns\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"iloc\"></a>\n",
    "### Pandas Slicing (a reminder...)\n",
    "\n",
    "`.iloc` is by position (position is unique), `.loc` is by label (label is not unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cast dataframe \n",
    "cast = pd.read_csv('../data/cast.csv', encoding='utf_8')\n",
    "cast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me rows 10 to 13 (python slicing style : exclusive of end) \n",
    "cast.iloc[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me columns 0 to 2 but all rows - use head()\n",
    "cast.iloc[:, 0:2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me rows 10 to 13 AND only columns 0 to 2\n",
    "cast.iloc[10:13, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE: get me rows 10 to 13 (pandas slicing style : inclusive of end)\n",
    "cast.loc[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me columns 'year' and 'type' by label but only for rows 5 to 10\n",
    "cast.loc[5:10,['year','type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example of positioning with `.iloc` and `loc`\n",
    "\n",
    "Look at the following data frame. It is a bad example because we have duplicate values for the index but that is legal in pandas. It's just a bad practice and we are doing it to illustrate the difference between positioning with `.iloc` and `loc`. To keep rows unique, though, internally, `pandas` has its own index which in this dataframe runs from `0` to `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['A', 'Z', 'A']\n",
    "famous = pd.DataFrame({'Elton': ['singer', 'Candle in the wind', 'male'],\n",
    "                  'Maraie': ['actress' , 'Do not know', 'female'],\n",
    "                  'num': np.random.randn(3)}, index=index)\n",
    "famous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing elements by label can bring up duplicates!!\n",
    "famous.loc['A']  # since we want all rows is the same as famous.loc['A',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing elements by position is unique - brings up only one row\n",
    "famous.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "## 2 - Plotting with matplotlib and beyond\n",
    "<br>\n",
    "<img style=\"float: center\" src=\"https://imgs.xkcd.com/comics/convincing.png\"> \n",
    "\n",
    "`matplotlib` is a very powerful `python` library for making scientific plots. \n",
    "\n",
    "We will not focus too much on the internal aspects of `matplotlib` in today's lab. There are many excellent tutorials out there for `matplotlib`.  For example,\n",
    "* [`matplotlib` homepage](https://matplotlib.org/)\n",
    "* [`matplotlib` tutorial](https://github.com/matplotlib/AnatomyOfMatplotlib)\n",
    "\n",
    "Conveying your findings convincingly is an absolutely crucial part of any analysis. Therefore, you must be able to write well and make compelling visuals.  Creating informative visuals is an involved process and we won't cover that in this lab.  However, part of creating informative data visualizations means generating *readable* figures.  If people can't read your figures or have a difficult time interpreting them, they won't understand the results of your work.  Here are some non-negotiable commandments for any plot:\n",
    "* Label $x$ and $y$ axes\n",
    "* Axes labels should be informative\n",
    "* Axes labels should be large enough to read\n",
    "* Make tick labels large enough\n",
    "* Include a legend if necessary\n",
    "* Include a title if necessary\n",
    "* Use appropriate line widths\n",
    "* Use different line styles for different lines on the plot\n",
    "* Use different markers for different lines\n",
    "\n",
    "There are other important elements, but that list should get you started on your way.\n",
    "\n",
    "We will work with `matplotlib` and `seaborn` for plotting in this class.  `matplotlib` is a very powerful `python` library for making scientific plots.  `seaborn` is a little more specialized in that it was developed for statistical data visualization.  We will cover some `seaborn` later in class. In the meantime you can look at the [seaborn documentation](https://seaborn.pydata.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's generate some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot some functions\n",
    "\n",
    "We will use the following three functions to make some plots:\n",
    "\n",
    "* Logistic function:\n",
    "  \\begin{align*}\n",
    "    f\\left(z\\right) = \\dfrac{1}{1 + be^{-az}}\n",
    "  \\end{align*}\n",
    "  where $a$ and $b$ are parameters.\n",
    "* Hyperbolic tangent:\n",
    "  \\begin{align*}\n",
    "    g\\left(z\\right) = b\\tanh\\left(az\\right) + c\n",
    "  \\end{align*}\n",
    "  where $a$, $b$, and $c$ are parameters.\n",
    "* Rectified Linear Unit:\n",
    "  \\begin{align*}\n",
    "    h\\left(z\\right) = \n",
    "    \\left\\{\n",
    "      \\begin{array}{lr}\n",
    "        z, \\quad z > 0 \\\\\n",
    "        \\epsilon z, \\quad z\\leq 0\n",
    "      \\end{array}\n",
    "    \\right.\n",
    "  \\end{align*}\n",
    "  where $\\epsilon < 0$ is a small, positive parameter.\n",
    "\n",
    "You are given the code for the first two functions.  Notice that $z$ is passed in as a `numpy` array and that the functions are returned as `numpy` arrays.  Parameters are passed in as floats.\n",
    "\n",
    "You should write a function to compute the rectified linear unit.  The input should be a `numpy` array for $z$ and a positive float for $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logistic(z: np.ndarray, a: float, b: float) -> np.ndarray:\n",
    "    \"\"\" Compute logistic function\n",
    "      Inputs:\n",
    "         a: exponential parameter\n",
    "         b: exponential prefactor\n",
    "         z: numpy array; domain\n",
    "      Outputs:\n",
    "         f: numpy array of floats, logistic function\n",
    "    \"\"\"\n",
    "    \n",
    "    den = 1.0 + b * np.exp(-a * z)\n",
    "    return 1.0 / den\n",
    "\n",
    "def stretch_tanh(z: np.ndarray, a: float, b: float, c: float) -> np.ndarray:\n",
    "    \"\"\" Compute stretched hyperbolic tangent\n",
    "      Inputs:\n",
    "         a: horizontal stretch parameter (a>1 implies a horizontal squish)\n",
    "         b: vertical stretch parameter\n",
    "         c: vertical shift parameter\n",
    "         z: numpy array; domain\n",
    "      Outputs:\n",
    "         g: numpy array of floats, stretched tanh\n",
    "    \"\"\"\n",
    "    return b * np.tanh(a * z) + c\n",
    "\n",
    "def relu(z: np.ndarray, eps: float = 0.01) -> np.ndarray:\n",
    "    \"\"\" Compute rectificed linear unit\n",
    "      Inputs:\n",
    "         eps: small positive parameter\n",
    "         z: numpy array; domain\n",
    "      Outputs:\n",
    "         h: numpy array; relu\n",
    "    \"\"\"\n",
    "    return np.fmax(z, eps * z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some plots.  First, let's just warm up and plot the logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5.0, 5.0, 100) # Equally spaced grid of 100 pts between -5 and 5\n",
    "\n",
    "f = logistic(x, 1.0, 1.0) # Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, f)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f')\n",
    "plt.title('Logistic Function')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures with subplots\n",
    "\n",
    "Let's start thinking about the plots as objects. We have the `figure` object which is like a matrix of smaller plots named `axes`. You can use array notation when handling it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1) # Get figure and axes objects\n",
    "\n",
    "ax.plot(x, f) # Make a plot\n",
    "\n",
    "# Create some labels\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f')\n",
    "ax.set_title('Logistic Function')\n",
    "\n",
    "# Grid\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it's *exactly* the same plot!  Notice, however, the use of `ax.set_xlabel()` instead of `plt.xlabel()`.  The difference is tiny, but you should be aware of it.  I will use this plotting syntax from now on.\n",
    "\n",
    "What else do we need to do to make this figure better?  Here are some options:\n",
    "* Make labels bigger!\n",
    "* Make line fatter\n",
    "* Make tick mark labels bigger\n",
    "* Make the grid less pronounced\n",
    "* Make figure bigger\n",
    "\n",
    "Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6)) # Make figure bigger\n",
    "\n",
    "# Make line plot\n",
    "ax.plot(x, f, lw=4)\n",
    "\n",
    "# Update ticklabel size\n",
    "ax.tick_params(labelsize=24)\n",
    "\n",
    "# Make labels\n",
    "ax.set_xlabel(r'$x$', fontsize=24) # Use TeX for mathematical rendering\n",
    "ax.set_ylabel(r'$f(x)$', fontsize=24) # Use TeX for mathematical rendering\n",
    "ax.set_title('Logistic Function', fontsize=24)\n",
    "\n",
    "ax.grid(True, lw=1.5, ls='--', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice:\n",
    "* `lw` stands for `linewidth`.  We could also write `ax.plot(x, f, linewidth=4)`\n",
    "* `ls` stands for `linestyle`.\n",
    "* `alpha` stands for transparency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing remaining to do is to change the $x$ limits.  Clearly these should go from $-5$ to $5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.savefig('logistic.png')\n",
    "\n",
    "# Put this in a markdown cell and uncomment this to check what you saved.\n",
    "# ![](../images/logistic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "If you want to see all the styles available, please take a look at the documentation.\n",
    "* [Line styles](https://matplotlib.org/2.0.1/api/lines_api.html#matplotlib.lines.Line2D.set_linestyle)\n",
    "* [Marker styles](https://matplotlib.org/2.0.1/api/markers_api.html#module-matplotlib.markers)\n",
    "* [Everything you could ever want](https://matplotlib.org/2.0.1/api/lines_api.html#matplotlib.lines.Line2D.set_marker)\n",
    "\n",
    "We haven't discussed it yet, but you can also put a legend on a figure.  You'll do that in the next exercise.  Here are some additional resources:\n",
    "* [Legend](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html)\n",
    "* [Grid](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.grid.html)\n",
    "\n",
    "`ax.legend(loc='best', fontsize=24);`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Do the following:\n",
    "* Make a figure with the logistic function, hyperbolic tangent, and rectified linear unit.\n",
    "* Use different line styles for each plot\n",
    "* Put a legend on your figure\n",
    "\n",
    "Here's an example of a figure:\n",
    "![](../images/nice_plots.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# First get the data\n",
    "f = logistic(x, 2.0, 1.0)\n",
    "g = stretch_tanh(x, 2.0, 0.5, 0.5)\n",
    "h = relu(x)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6)) # Create figure object\n",
    "\n",
    "# Make actual plots\n",
    "# (Notice the label argument!)\n",
    "ax.plot(x, f, lw=4, ls='-', label=r'$L(x;1)$')\n",
    "ax.plot(x, g, lw=4, ls='--', label=r'$\\tanh(2x)$')\n",
    "ax.plot(x, h, lw=4, ls='-.', label=r'$relu(x; 0.01)$')\n",
    "\n",
    "# Make the tick labels readable\n",
    "ax.tick_params(labelsize=24)\n",
    "\n",
    "# Set axes limits to make the scale nice\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(h.min(), 1.1)\n",
    "\n",
    "# Make readable labels\n",
    "ax.set_xlabel(r'$x$', fontsize=24)\n",
    "ax.set_ylabel(r'$h(x)$', fontsize=24)\n",
    "ax.set_title('Activation Functions', fontsize=24)\n",
    "\n",
    "# Set up grid\n",
    "ax.grid(True, lw=1.75, ls='--', alpha=0.75)\n",
    "\n",
    "# Put legend on figure\n",
    "ax.legend(loc='best', fontsize=24);\n",
    "\n",
    "fig.savefig('../images/nice_plots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "These figures look nice in the plot and it makes sense for comparison. Now let's put the 3 different figures in separate plots.\n",
    "\n",
    "* Make a separate plot for each figure and line them up on the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/three_subplots.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Make a grid of 2 x 3 separate plots, 3 will be empty. Just plot the functions and do not worry about cosmetics. We just want you ro see the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/six_subplots.py\n",
    "\n",
    "# First get the data\n",
    "f = logistic(x, 2.0, 1.0)\n",
    "g = stretch_tanh(x, 2.0, 0.5, 0.5)\n",
    "h = relu(x)\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(20,6)) # Create figure object\n",
    "\n",
    "# Make actual plots\n",
    "ax[0][0].plot(x, f, lw=4, ls='-', label=r'$L(x;1)$')\n",
    "ax[1][1].plot(x, g, lw=4, ls='--', label=r'$\\tanh(2x)$')\n",
    "ax[1][2].plot(x, h, lw=4, ls='-.', label=r'$relu(x; 0.01)$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "## 3 - Simple Linear Regression\n",
    "\n",
    "Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work.\n",
    "\n",
    "\n",
    "### Linear regression with a toy dataset\n",
    "We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations.  Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$,\n",
    "\n",
    "\\begin{align*}\n",
    "(x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}.\n",
    "\\end{align*}\n",
    "\n",
    "To be very concrete, let's set the values of the predictors and responses.\n",
    "\n",
    "\\begin{equation*}\n",
    "(x , y) = \\{(1, 2), (2, 2), (3, 4)\\}\n",
    "\\end{equation*}\n",
    "\n",
    "There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the *least-squares sense*, as discussed in lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise (for home)</b></div>\n",
    "\n",
    "* Make two numpy arrays out of this data, x_train and y_train\n",
    "* Check the dimentions of these arrays\n",
    "* Try to reshape them into a different shape\n",
    "* Make points into a very simple scatterplot\n",
    "* Make a better scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "x_train = np.array([1,2,3])\n",
    "y_train = np.array([2,3,6])\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(3,1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1) (3,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/simple_scatterplot.py\n",
    "# Make a simple scatterplot\n",
    "plt.scatter(x_train,y_train)\n",
    "\n",
    "# check dimensions \n",
    "print(x_train.shape,y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16cd5fc8208>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/nice_scatterplot.py\n",
    "def nice_scatterplot(x, y, title):\n",
    "    # font size\n",
    "    f_size = 18\n",
    "    \n",
    "    # make the figure\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,5)) # Create figure object\n",
    "\n",
    "    # set axes limits to make the scale nice\n",
    "    ax.set_xlim(np.min(x)-1, np.max(x) + 1)\n",
    "    ax.set_ylim(np.min(y)-1, np.max(y) + 1)\n",
    "\n",
    "    # adjust size of tickmarks in axes\n",
    "    ax.tick_params(labelsize = f_size)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.tick_params(labelbottom=False,  bottom=False)\n",
    "    \n",
    "    # adjust size of axis label\n",
    "    ax.set_xlabel(r'$x$', fontsize = f_size)\n",
    "    ax.set_ylabel(r'$y$', fontsize = f_size)\n",
    "    \n",
    "    # set figure title label\n",
    "    ax.set_title(title, fontsize = f_size)\n",
    "\n",
    "    # you may set up grid with this \n",
    "    ax.grid(True, lw=1.75, ls='--', alpha=0.15)\n",
    "\n",
    "    # make actual plot (Notice the label argument!)\n",
    "    #ax.scatter(x, y, label=r'$my points$')\n",
    "    #ax.scatter(x, y, label='$my points$')\n",
    "    ax.scatter(x, y, label=r'$my\\,points$')\n",
    "    ax.legend(loc='best', fontsize = f_size);\n",
    "    \n",
    "    return ax\n",
    "\n",
    "nice_scatterplot(x_train, y_train, 'hello nice plot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Formulae\n",
    "Linear regression is special among the models we study because it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data.\n",
    "\n",
    "For the single predictor case it is:\n",
    "    \\begin{align}\n",
    "      \\beta_1 &= \\frac{\\sum_{i=1}^n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}\\\\\n",
    "      \\beta_0 &= \\bar{y} - \\beta_1\\bar{x}\\\n",
    "    \\end{align}\n",
    "    \n",
    "Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model from scratch\n",
    "In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set.  Let's walk through the code.\n",
    "\n",
    "We have to reshape our arrrays to 2D. We will see later why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* make an array with shape (2,3)\n",
    "* reshape it to a size that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "xx = np.array([[1,2,3],[4,6,8]])\n",
    "xxx = xx.reshape(-1,2)\n",
    "xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to be a proper 2D array\n",
    "x_train = x_train.reshape(x_train.shape[0], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() ()\n"
     ]
    }
   ],
   "source": [
    "# first, compute means\n",
    "y_bar = np.mean(y_train)\n",
    "x_bar = np.mean(x_train)\n",
    "\n",
    "# build the two terms\n",
    "numerator = np.sum( (x_train - x_bar)*(y_train - y_bar) )\n",
    "denominator = np.sum((x_train - x_bar)**2)\n",
    "\n",
    "print(numerator.shape, denominator.shape) #check shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why the empty brackets? (The numerator and denominator are scalars, as expected.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best-fit line is -0.33 + 2.00 * x\n",
      "The best fit is -0.3333333333333335\n"
     ]
    }
   ],
   "source": [
    "#slope beta1\n",
    "beta_1 = numerator/denominator\n",
    "\n",
    "#intercept beta0\n",
    "beta_0 = y_bar - beta_1*x_bar\n",
    "\n",
    "print(\"The best-fit line is {0:3.2f} + {1:3.2f} * x\".format(beta_0, beta_1))\n",
    "print(f'The best fit is {beta_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Turn the code from the above cells into a function called `simple_linear_regression_fit`, that inputs the training data and returns `beta0` and `beta1`.\n",
    "\n",
    "To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output.\n",
    "\n",
    "```python\n",
    "def simple_linear_regression_fit(x_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    return\n",
    "```\n",
    "\n",
    "Check your function by calling it with the training data from above and printing out the beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/simple_linear_regression_fit.py\n",
    "def simple_linear_regression_fit(x_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x_train: a (num observations by 1) array holding the values of the predictor variable\n",
    "    y_train: a (num observations by 1) array holding the values of the response variable\n",
    "\n",
    "    Returns:\n",
    "    beta_vals:  a (num_features by 1) array holding the intercept and slope coeficients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check input array sizes\n",
    "    if len(x_train.shape) < 2:\n",
    "        print(\"Reshaping features array.\")\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1)\n",
    "\n",
    "    if len(y_train.shape) < 2:\n",
    "        print(\"Reshaping observations array.\")\n",
    "        y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "    # first, compute means\n",
    "    y_bar = np.mean(y_train)\n",
    "    x_bar = np.mean(x_train)\n",
    "\n",
    "    # build the two terms\n",
    "    numerator = np.sum( (x_train - x_bar)*(y_train - y_bar) )\n",
    "    denominator = np.sum((x_train - x_bar)**2)\n",
    "    \n",
    "    #slope beta1\n",
    "    beta_1 = numerator/denominator\n",
    "\n",
    "    #intercept beta0\n",
    "    beta_0 = y_bar - beta_1*x_bar\n",
    "\n",
    "    return np.array([beta_0,beta_1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's run this function and see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping features array.\n",
      "Reshaping observations array.\n",
      "The best-fit line is 0.666667 + 1.000000 * x\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([1 ,2, 3])\n",
    "y_train = np.array([2, 2, 4])\n",
    "\n",
    "betas = simple_linear_regression_fit(x_train, y_train)\n",
    "\n",
    "beta_0 = betas[0]\n",
    "beta_1 = betas[1]\n",
    "\n",
    "print(\"The best-fit line is {0:8.6f} + {1:8.6f} * x\".format(beta_0, beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Do the values of `beta0` and `beta1` seem reasonable?\n",
    "* Plot the training data using a scatter plot.\n",
    "* Plot the best fit line with `beta0` and `beta1` together with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/best_fit_scatterplot.py\n",
    "fig_scat, ax_scat = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "# Plot best-fit line\n",
    "x_train = np.array([[1, 2, 3]]).T\n",
    "\n",
    "best_fit = beta_0 + beta_1 * x_train\n",
    "\n",
    "ax_scat.scatter(x_train, y_train, s=300, label='Training Data')\n",
    "ax_scat.plot(x_train, best_fit, ls='--', label='Best Fit Line')\n",
    "\n",
    "ax_scat.set_xlabel(r'$x_{train}$')\n",
    "ax_scat.set_ylabel(r'$y$');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of `beta0` and `beta1` seem roughly reasonable.  They capture the positive correlation.  The line does appear to be trying to get as close as possible to all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "## 4 - Building a model with `statsmodels` and `sklearn`\n",
    "\n",
    "Now that we can concretely fit the training data from scratch, let's learn two `python` packages to do it all for us:\n",
    "* [statsmodels](http://www.statsmodels.org/stable/regression.html) and \n",
    "* [scikit-learn (sklearn)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "Our goal  is to show how to implement simple linear regression with these packages.  For an important sanity check, we compare the $\\beta$ values from `statsmodels` and `sklearn` to the $\\beta$ values that we found from above with our own implementation.\n",
    "\n",
    "For the purposes of this lab, `statsmodels` and `sklearn` do the same thing.  More generally though, `statsmodels` tends to be easier for inference \\[finding the values of the slope and intercept and dicussing uncertainty in those values\\], whereas `sklearn` has machine-learning algorithms and is better for prediction \\[guessing y values for a given x value\\]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for.\n",
    "\n",
    "**Note:** `statsmodels` and `sklearn` are different packages!  Unless we specify otherwise, you can use either one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for `statsmodels`.  `Statsmodels` does not by default include the column of ones in the $X$ matrix, so we include it manually with `sm.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]]\n",
      "The regression coef from statsmodels are: beta_0 = 0.666667 and beta_1 = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# create the X matrix by appending a column of ones to x_train\n",
    "X = sm.add_constant(x_train)\n",
    "\n",
    "# this is the same matrix as in our scratch problem!\n",
    "print(X)\n",
    "\n",
    "# build the OLS model (ordinary least squares) from the training data\n",
    "toyregr_sm = sm.OLS(y_train, X)\n",
    "\n",
    "# do the fit and save regression info (parameters, etc) in results_sm\n",
    "results_sm = toyregr_sm.fit()\n",
    "\n",
    "# pull the beta parameters out from results_sm\n",
    "beta0_sm = results_sm.params[0]\n",
    "beta1_sm = results_sm.params[1]\n",
    "\n",
    "print(f'The regression coef from statsmodels are: beta_0 = {beta0_sm:8.6f} and beta_1 = {beta1_sm:8.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the beta parameters, `results_sm` contains a ton of other potentially useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.750\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     3.000\n",
      "Date:                Sat, 21 Sep 2019   Prob (F-statistic):              0.333\n",
      "Time:                        16:07:33   Log-Likelihood:                -2.0007\n",
      "No. Observations:                   3   AIC:                             8.001\n",
      "Df Residuals:                       1   BIC:                             6.199\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6667      1.247      0.535      0.687     -15.181      16.514\n",
      "x1             1.0000      0.577      1.732      0.333      -6.336       8.336\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   3.000\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.531\n",
      "Skew:                          -0.707   Prob(JB):                        0.767\n",
      "Kurtosis:                       1.500   Cond. No.                         6.79\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn our attention to the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the least squares model\n",
    "toyregr = linear_model.LinearRegression()\n",
    "\n",
    "# save regression info (parameters, etc) in results_skl\n",
    "results = toyregr.fit(x_train, y_train)\n",
    "\n",
    "# pull the beta parameters out from results_skl\n",
    "beta0_skl = toyregr.intercept_\n",
    "beta1_skl = toyregr.coef_[0]\n",
    "\n",
    "print(\"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f}\".format(beta0_skl, beta1_skl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should feel pretty good about ourselves now, and we're ready to move on to a real problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `scikit-learn` library and the shape of things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into a \"real\" problem, let's discuss more of the details of `sklearn`.\n",
    "\n",
    "`Scikit-learn` is the main `Python` machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as `train_test_split()`. \n",
    "\n",
    "Use the following to add the library into your code:\n",
    "\n",
    "```python\n",
    "import sklearn \n",
    "```\n",
    "\n",
    "In `scikit-learn`, an **estimator** is a Python object that implements the methods `fit(X, y)` and `predict(T)`\n",
    "\n",
    "Let's see the structure of `scikit-learn` needed to make these fits. `fit()` always takes two arguments:\n",
    "```python\n",
    "estimator.fit(Xtrain, ytrain)\n",
    "```\n",
    "We will consider two estimators in this lab: `LinearRegression` and `KNeighborsRegressor`.\n",
    "\n",
    "It is very important to understand that `Xtrain` must be in the form of a **2x2 array** with each row corresponding to one sample, and each column corresponding to the feature values for that sample.\n",
    "\n",
    "`ytrain` on the other hand is a simple array of responses.  These are continuous for regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/featurematrix.png)\n",
    "\n",
    "<!--![](../images/sklearn2.jpg)-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice with `sklearn` and a real dataset\n",
    "We begin by loading up the `mtcars` dataset. This data was extracted from the 1974 Motor Trend US magazine, and comprises of fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). We will load this data to a dataframe with 32 observations on 11 (numeric) variables. Here is an explanation of the features:\n",
    "\n",
    "- `mpg` is Miles/(US) gallon \n",
    "- `cyl` is Number of cylinders, \n",
    "- `disp` is\tDisplacement (cu.in.), \n",
    "- `hp` is\tGross horsepower, \n",
    "- `drat` is\tRear axle ratio, \n",
    "- `wt` is the Weight (1000 lbs), \n",
    "- `qsec` is 1/4 mile time,\n",
    "- `vs` is Engine (0 = V-shaped, 1 = straight), \n",
    "- `am` is Transmission (0 = automatic, 1 = manual), \n",
    "- `gear` is the Number of forward gears, \n",
    "- `carb` is\tNumber of carburetors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load mtcars\n",
    "dfcars = pd.read_csv(\"../data/mtcars.csv\")\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the column title \n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"car name\"})\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for values: how many cars have 4 gears?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfcars[dfcars.gear == 4].drop_duplicates(subset='car name', keep='first'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the dataset into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set random_state to get the same split every time\n",
    "traindf, testdf = train_test_split(dfcars, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing set is around 20% of the total data; training set is around 80%\n",
    "print(\"Shape of full dataset is: {0}\".format(dfcars.shape))\n",
    "print(\"Shape of training dataset is: {0}\".format(traindf.shape))\n",
    "print(\"Shape of test dataset is: {0}\".format(testdf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have training and test data.  We still need to select a predictor and a response from this dataset.  Keep in mind that we need to choose the predictor and response from both the training and test set.  You will do this in the exercises below.  However, we provide some starter code for you to get things going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response variable that we're interested in\n",
    "y_train = traindf.mpg\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Use slicing to get the same vector `y_train`\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice the shape of `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array reshape\n",
    "This is a 1D array as should be the case with the **Y** array.  Remember, `sklearn` requires a 2D array only for the predictor array.  You will have to pay close attention to this in the exercises later. `Sklearn` doesn't care too much about the shape of `y_train`.\n",
    "\n",
    "The whole reason we went through that whole process was to show you how to reshape your data into the correct format.\n",
    "\n",
    "**IMPORTANT:** Remember that your response variable `ytrain` can be a vector but your predictor variable `xtrain` ***must*** be an array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "## 5 - Example: Simple linear regression with automobile data\n",
    "We will now use `sklearn` to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose the variables that we think will be good predictors for the dependent variable `mpg`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise in pairs</b></div>\n",
    "\n",
    "* Pick one variable to use as a predictor for simple linear regression.  Discuss your reasons with the person next to you.  \n",
    "* Justify your choice with some visualizations.  \n",
    "* Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wt = dfcars.wt\n",
    "x_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cars_simple_EDA.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Use `sklearn` to fit the training data using simple linear regression.\n",
    "* Use the model to make mpg predictions on the test set.  \n",
    "* Plot the data and the prediction.  \n",
    "* Print out the mean squared error for the training set and the test set and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dfcars = pd.read_csv(\"../data/mtcars.csv\")\n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n",
    "\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(dfcars, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.array(traindf.mpg)\n",
    "X_train = np.array(traindf.wt)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(testdf.mpg)\n",
    "X_test = np.array(testdf.wt)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take another look at our data\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And out train and test sets \n",
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create linear model\n",
    "regression = LinearRegression()\n",
    "\n",
    "#fit linear model\n",
    "regression.fit(X_train, y_train)\n",
    "\n",
    "predicted_y = regression.predict(X_test)\n",
    "\n",
    "r2 = regression.score(X_test, y_test)\n",
    "print(f'R^2 = {r2:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression.score(X_train, y_train))\n",
    "\n",
    "print(mean_squared_error(predicted_y, y_test))\n",
    "print(mean_squared_error(y_train, regression.predict(X_train)))\n",
    "\n",
    "print('Coefficients: \\n', regression.coef_[0], regression.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.plot(y_test, predicted_y, 'o')\n",
    "grid = np.linspace(np.min(dfcars.mpg), np.max(dfcars.mpg), 100)\n",
    "ax.plot(grid, grid, color=\"black\") # 45 degree line\n",
    "ax.set_xlabel(\"actual y\")\n",
    "ax.set_ylabel(\"predicted y\")\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "ax1.plot(dfcars.wt, dfcars.mpg, 'o')\n",
    "xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n",
    "ax1.plot(xgrid, regression.predict(xgrid.reshape(100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "## 6 - $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're familiar with `sklearn`, you're ready to do a KNN regression.  \n",
    "\n",
    "Sklearn's regressor is called `sklearn.neighbors.KNeighborsRegressor`. Its main parameter is the `number of nearest neighbors`. There are other parameters such as the distance metric (default for 2 order is the Euclidean distance). For a list of all the parameters see the [Sklearn kNN Regressor Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html).\n",
    "\n",
    "Let's use $5$ nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of neighbors\n",
    "k = 5\n",
    "knnreg = KNeighborsRegressor(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regressor - make sure your numpy arrays are the right shape\n",
    "knnreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the outcome on the train set using R^2\n",
    "r2_train = knnreg.score(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(f'kNN model with {k} neighbors gives R^2 on the train set: {r2_train:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Calculate and print the $R^{2}$ score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so good? Lets vary the number of neighbors and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3f06aab0155f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mknnreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mknnreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Store the regressors in a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mregdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknnreg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \"\"\"\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 3]"
     ]
    }
   ],
   "source": [
    "# Make our lives easy by storing the different regressors in a dictionary\n",
    "regdict = {}\n",
    "\n",
    "# Make our lives easier by entering the k values from a list\n",
    "k_list = [1, 2, 4, 15]\n",
    "\n",
    "# Do a bunch of KNN regressions\n",
    "for k in k_list:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k)\n",
    "    knnreg.fit(X_train, y_train)\n",
    "    # Store the regressors in a dictionary\n",
    "    regdict[k] = knnreg \n",
    "\n",
    "# Print the dictionary to see what we have\n",
    "regdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot all the k values in same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (25, 1) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-83a080e6a80f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m         \"\"\"\n\u001b[0;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (25, 1) and (3,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.plot(X_train, y_train, 'o', label=\"data\")\n",
    "\n",
    "xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n",
    "\n",
    "# let's unpack the dictionary to its elements (items) which is the k and Regressor\n",
    "for k, regressor in regdict.items():\n",
    "    predictions = regressor.predict(xgrid.reshape(-1,1)) \n",
    "    ax.plot(xgrid, predictions, label=\"{}-NN\".format(k))\n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Explain what you see in the graph. **Hint** Notice how the $1$-NN goes through every point on the training set but utterly fails elsewhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the scores on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-407bb5460251>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Fit the model to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mknnreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Calculate R^2 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \"\"\"\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 3]"
     ]
    }
   ],
   "source": [
    "ks = range(1, 15) # Grid of k's\n",
    "scores_train = [] # R2 scores\n",
    "for k in ks:\n",
    "    # Create KNN model\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k) \n",
    "    \n",
    "    # Fit the model to training data\n",
    "    knnreg.fit(X_train, y_train) \n",
    "    \n",
    "    # Calculate R^2 score\n",
    "    score_train = knnreg.score(X_train, y_train) \n",
    "    scores_train.append(score_train)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.plot(ks, scores_train,'o-')\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.set_ylabel(r'$R^{2}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Why do we get a perfect $R^2$ at k=1 for the training set?\n",
    "* Make the same plot as above on the *test* set.\n",
    "* What is the best $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2e08ff4f68a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mknnreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Create KNN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mknnreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Fit the model to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mscore_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknnreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calculate R^2 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mscores_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \"\"\"\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 3]"
     ]
    }
   ],
   "source": [
    "# %load solutions/knn_regression.py\n",
    "ks = range(1, 7) # Grid of k's\n",
    "scores_test = [] # R2 scores\n",
    "for k in ks:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k) # Create KNN model\n",
    "    knnreg.fit(X_train, y_train) # Fit the model to training data\n",
    "    score_test = knnreg.score(X_test, y_test) # Calculate R^2 score\n",
    "    scores_test.append(score_test)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.plot(ks, scores_test,'o-', ms=12)\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.set_ylabel(r'$R^{2}$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution to previous exercise\n",
    "r2_test = knnreg.score(X_test, y_test)\n",
    "print(f'kNN model with {k} neighbors gives R^2 on the test set: {r2_test:.5}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
